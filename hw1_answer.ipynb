{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f18c2ff5",
   "metadata": {},
   "source": [
    "### 1. 使用np.exp()实现sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b61495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def basic_sigmoid(x):\n",
    "    '''\n",
    "   计算sigmoid函数 \n",
    "    '''\n",
    "    # 开始\n",
    "    s = 1/(1+np.exp(-x))\n",
    "    # 结束\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8bc6b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01798620996209156"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b1e253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04742587, 0.5       , 0.99330715])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_sigmoid(np.array([-3, 0, 5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea6ec0",
   "metadata": {},
   "source": [
    "### 实现Sigmoid gradient (梯度)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3578e3",
   "metadata": {},
   "source": [
    "完成sigmoid的梯度函数，用它去计算sigmoid相对于其输入x的梯度 $\\sigma'(x)=\\sigma(x)(1-\\sigma(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11637d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "   计算sigmoid function函数相对于其输入x的梯度 (也称为斜率或者导数)\n",
    "    '''\n",
    "    # 开始\n",
    "    ds = basic_sigmoid(x)*(1-basic_sigmoid(x))\n",
    "    # 结束\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d37b602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017662706213291118"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8126a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.51766597e-02, 2.50000000e-01, 6.64805667e-03, 2.06115369e-09])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_derivative(np.array([-3, 0, 5, 20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f796b9c",
   "metadata": {},
   "source": [
    "### 3.手写数字'0'和'1'分类的logistic回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c49ab3",
   "metadata": {},
   "source": [
    "#### 要求\n",
    "实现一个学习算法的整体结构：\n",
    "\n",
    "* 获取并定义模型输入\n",
    "* 初始化参数\n",
    "* 计算成本函数及其梯度\n",
    "* 使用优化算法(梯度下降).\n",
    "  * 计算当前损失(正向传播)。\n",
    "  * 计算当前梯度(反向传摄)。\n",
    "  * 更新参数 (梯度下降)\n",
    "  \n",
    "请实现相关函数，其中读取数据不需要实现。并在主模型函数中场写逻辑"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141b8e0",
   "metadata": {},
   "source": [
    "#### 读取数据\n",
    "1. 按照向量化伪代码实现的形状要求将样本数据进行转换 \n",
    "2. 标准化数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bfe2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c988989",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root=\"./data/\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0428b467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a036c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a680e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root=\"./data/\", train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235a2c87",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.4549, 0.4902, 0.6706, 1.0000, 1.0000, 0.5882,\n",
       "          0.3647, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.6627, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.8549, 0.1176, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.6627, 0.9922, 0.9922, 0.9922, 0.8353, 0.5569, 0.6902, 0.9922,\n",
       "          0.9922, 0.4784, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2039,\n",
       "          0.9804, 0.9922, 0.8235, 0.1255, 0.0471, 0.0000, 0.0235, 0.8078,\n",
       "          0.9922, 0.5490, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3020,\n",
       "          0.9843, 0.8235, 0.0980, 0.0000, 0.0000, 0.0000, 0.4784, 0.9725,\n",
       "          0.9922, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1216, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.8196, 0.9922,\n",
       "          0.9922, 0.2549, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4588, 0.9686, 0.9922,\n",
       "          0.7765, 0.0392, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.2980, 0.9686, 0.9922, 0.9059,\n",
       "          0.2471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.5020, 0.9922, 0.9922, 0.5647,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.6902, 0.9647, 0.9922, 0.6235, 0.0471,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0980, 0.9176, 0.9922, 0.9137, 0.1373, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.7765, 0.9922, 0.9922, 0.5529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3059, 0.9725, 0.9922, 0.7412, 0.0471, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0745, 0.7843, 0.9922, 0.9922, 0.5529, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5255, 0.9922, 0.9922, 0.6784, 0.0471, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.9725, 0.9922, 0.9922, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.9725, 0.9922, 0.9922, 0.1686, 0.0784, 0.0784, 0.0784, 0.0784,\n",
       "          0.0196, 0.0000, 0.0196, 0.0784, 0.0784, 0.1451, 0.5882, 0.5882,\n",
       "          0.5882, 0.5765, 0.0392, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.9725, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.6588, 0.5608, 0.6510, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.4824, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.6824, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9922, 0.9765, 0.9686, 0.9686, 0.6627,\n",
       "          0.4588, 0.4588, 0.2235, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.4627, 0.4824, 0.4824, 0.4824, 0.6510, 0.9922, 0.9922,\n",
       "          0.9922, 0.6078, 0.4824, 0.4824, 0.1608, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfa8ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "test_X = []\n",
    "train_Y = []\n",
    "test_Y = []\n",
    "class_1 = 1\n",
    "class_0 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "832a896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10000):\n",
    "    if test_data[i][1]==class_1 and i < 8000:\n",
    "        train_X.append(test_data[i][0].numpy().reshape(-1,))\n",
    "        train_Y.append(np.array([1]))\n",
    "    if test_data[i][1]==class_0 and i < 8000:\n",
    "        train_X.append(test_data[i][0].numpy().reshape(-1,))\n",
    "        train_Y.append(np.array([0]))\n",
    "    if test_data[i][1]==class_1 and i >= 8000:\n",
    "        test_X.append(test_data[i][0].numpy().reshape(-1,))\n",
    "        test_Y.append(np.array([1]))\n",
    "    if test_data[i][1]==class_0 and i >= 8000:\n",
    "        test_X.append(test_data[i][0].numpy().reshape(-1,))\n",
    "        test_Y.append(np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccd8cecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 1678) (784, 437) (1, 1678) (1, 437)\n"
     ]
    }
   ],
   "source": [
    "train_X = np.array(train_X).T\n",
    "test_X = np.array(test_X).T\n",
    "train_Y = np.array(train_Y).T\n",
    "test_Y = np.array(test_Y).T\n",
    "print(train_X.shape, test_X.shape, train_Y.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d6b1ea",
   "metadata": {},
   "source": [
    "### 初始化网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e60cb34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(shape):\n",
    "    \"\"\"\n",
    "    创建一个形状为(1,shape)的w参数和b=0\n",
    "    \"\"\"\n",
    "    ### 开始\n",
    "    w = np.zeros((1,shape))\n",
    "    b = 0\n",
    "    ### 结束\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35771c0e",
   "metadata": {},
   "source": [
    "### 前向和反向传播\n",
    "根据损失函数、前后传播向量化代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8b4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    参数：网络参数w(1*shape),b(1)  和    数据X(shape*N_sample),Y(1*N_sample)\n",
    "    Return:\n",
    "    损失cost，参数w的梯度dw(1*shape)、参数b的梯度db(1)\n",
    "    \"\"\"\n",
    "    # -------------前向传播--------------\n",
    "    ### 开始\n",
    "    z = np.dot(w, X) + b\n",
    "    Y_hat = basic_sigmoid(z)\n",
    "    cost = np.mean(-Y*np.log(Y_hat) - (1-Y)*np.log(1-Y_hat))\n",
    "    ### 结束\n",
    "    \n",
    "    # -------------反向传播--------------\n",
    "    ### 开始\n",
    "    dz = Y_hat-Y\n",
    "    dw = np.dot(Y_hat-Y,X.T)/X.shape[1]\n",
    "    db = np.mean(dz)\n",
    "    ### 结束\n",
    "    \n",
    "    grads = {'dw':dw, 'db':db}\n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc56293f",
   "metadata": {},
   "source": [
    "### 优化过程\n",
    "实现优化函数,全局的参数随着$w,b$对损失$J$进行优化改变。<br>\n",
    "给定学习率$\\alpha$下，对参数$\\theta$实行$\\theta=\\theta-\\alpha d\\theta $。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b932824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "    权重w，偏置b，特征X，目标值Y，总迭代次数num_iterations，学习率learning_rate\n",
    "    Returns：\n",
    "    params：更新后的参数字典\n",
    "    grads：梯度\n",
    "    costs：每次迭代的cost构成的列表\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        # ---------调用梯度计算的函数，并据此更新参数----------\n",
    "        ### 开始\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        w = w - learning_rate*grads['dw']\n",
    "        b = b - learning_rate*grads['db']\n",
    "        \n",
    "        ### 结束        \n",
    "        \n",
    "        costs.append(cost)\n",
    "        if i % 10 == 0:\n",
    "            print('损失函数 %i:%f' %(i, cost))\n",
    "        \n",
    "    params = {'w':w, 'b':b}\n",
    "    return params, costs  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd2ed7c",
   "metadata": {},
   "source": [
    "### 预测函数（不需要实现，后面调用即可）\n",
    "利用得出的参数采进行测试得出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d44f8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    \"\"\"\n",
    "    利用训练好的参数w和b和输入X\n",
    "    此时X可以为训练集(样本内预测),也可以为测试集(样本外预测)\n",
    "    return：预测结果\n",
    "    \"\"\"\n",
    "    # 计算结果\n",
    "    A = basic_sigmoid(np.dot(w, X) + b)\n",
    "    Y_pre = np.where(A>0.5, 1, 0)\n",
    "    \n",
    "    return Y_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd25f12",
   "metadata": {},
   "source": [
    "### 整体逻辑实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "591d83ae",
   "metadata": {},
   "outputs": [],
   "source": [
    " def model(X_train, Y_train, X_test, Y_test, num_iterations=100, learning_rate=0.01):\n",
    "    ### 开始\n",
    "    # 调用函数：初始化参数\n",
    "    w,b = initialize_with_zeros(X_train.shape[0])\n",
    "    # 调用函数：梯度下降法优化参数\n",
    "    params, costs  = optimize(w, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    # 获取训练参数\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    # 预测结果\n",
    "    Y_pre_train = predict(w, b, train_X)    \n",
    "    Y_pre_test = predict(w, b, test_X)    \n",
    "    ### 结束\n",
    "    \n",
    "    # 打印准确率\n",
    "    print('--'*50)\n",
    "    print('训练集准确率%f'%(np.mean(Y_pre_train==Y_train)*100))\n",
    "    print('测试集准确率%f'%(np.mean(Y_pre_test==Y_test)*100))  \n",
    "    \n",
    "    answers = {'costs':costs,\n",
    "        'Y_prediction_train':Y_pre_train,\n",
    "        'Y_prediction_test':Y_pre_test,\n",
    "        'w':w, 'b':b,\n",
    "        'num_iterations':num_iterations,\n",
    "        'learning_rate':learning_rate}\n",
    "    \n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79d90557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "损失函数 0:0.693147\n",
      "损失函数 10:0.184616\n",
      "损失函数 20:0.108454\n",
      "损失函数 30:0.078364\n",
      "损失函数 40:0.062121\n",
      "损失函数 50:0.051884\n",
      "损失函数 60:0.044806\n",
      "损失函数 70:0.039600\n",
      "损失函数 80:0.035598\n",
      "损失函数 90:0.032418\n",
      "损失函数 100:0.029826\n",
      "损失函数 110:0.027668\n",
      "损失函数 120:0.025841\n",
      "损失函数 130:0.024272\n",
      "损失函数 140:0.022910\n",
      "损失函数 150:0.021714\n",
      "损失函数 160:0.020655\n",
      "损失函数 170:0.019710\n",
      "损失函数 180:0.018862\n",
      "损失函数 190:0.018094\n",
      "----------------------------------------------------------------------------------------------------\n",
      "训练集准确率99.940405\n",
      "测试集准确率99.542334\n"
     ]
    }
   ],
   "source": [
    "d = model(train_X, train_Y, test_X, test_Y, num_iterations = 200, learning_rate = 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
